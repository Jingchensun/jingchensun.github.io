<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Hypothesis Tests (Statistic Notes)</title>
  <link rel="stylesheet" href="../../stylesheet.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    h1 {
      text-align: center;
      color: #527bbd;
      font-size: 165%;
      margin-bottom: 40px;
      border-bottom: none;
    }

    h2 {
      color: #2471A3;
      font-size: 125%;
      margin-top: 2em;
    }

    p, ul, li {
      font-size: 16px;
      line-height: 1.6;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
      margin-bottom: 30px;
    }

    table th, table td {
      border: 1px solid #ccc;
      padding: 10px;
      text-align: left;
    }

    table th {
      background-color: #f2f2f2;
    }

    hr {
      border: none;
      border-top: 1px solid #ccc;
      margin: 40px 0;
    }
  </style>
</head>

<body>
  <div id="layout-content" style="max-width: 960px; margin: 30px auto; padding: 0 50px;">

    <h1>Chapter 8: Classical Inference and Hypothesis Testing</h1>

    <h2>Section 8.1: Hypothesis Tests – 1 Population</h2>
    <p>Example: SAT scores are normally distributed with unknown mean \( \mu \), known standard deviation \( \sigma \).</p>
    <p>Population: \( X_p \sim \mathcal{N}(515, 116^2) \)</p>
    <p>From a random sample: \( \bar{X} = 555 \), \( n = 25 \)</p>

    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: \mu = 515 \)</li>
      <li>\( H_A: \mu > 515 \)</li>
    </ul>

    <p><strong>Z-statistic:</strong></p>
    <p>\( Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} = \frac{555 - 515}{116 / \sqrt{25}} = 1.724 \)</p>
    <p><strong>P-value:</strong> \( P(Z \ge 1.724) \approx 0.042 \)</p>
    <p><strong>Interpretation:</strong> Under \( H_0 \), there is a 4.2% chance to observe such a high sample mean. Hence, likely Sodor students have higher SAT scores.</p>

    <hr>

    <h2>Summary of 1 Population Results</h2>
    <table>
      <thead>
        <tr>
          <th>Sample</th>
          <th>Test Statistic</th>
          <th>Distribution</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>\( X_n \sim \mathcal{N}(\mu, \sigma^2) \), \( \sigma \) known</td>
          <td>\( Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \)</td>
          <td>\( Z \sim \mathcal{N}(0,1) \)</td>
        </tr>
        <tr>
          <td>\( X_n \sim \mathcal{N}(\mu, \sigma^2) \), \( \sigma \) unknown</td>
          <td>\( T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \)</td>
          <td>\( T \sim t(n - 1) \)</td>
        </tr>
        <tr>
          <td>\( Y \sim \text{Binomial}(n, p) \), exact binomial</td>
          <td>—</td>
          <td>Exact binomial</td>
        </tr>
        <tr>
          <td>\( Y \sim \text{Bin}(n, p) \), large \( n \)</td>
          <td>\( Z = \frac{Y \pm 0.5 - np}{\sqrt{np(1 - p)}} \)</td>
          <td>\( Z \sim \mathcal{N}(0, 1) \) with continuity correction</td>
        </tr>
      </tbody>
    </table>

    <hr>

    <h2>Section 8.2: Bootstrap t-test for Mean</h2>
    <p>Given \( X_i \sim F(\mu, \sigma^2) \) (distribution unknown), define:
      \[ T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \]
    </p>
    <p>Example: \( X \sim \text{Exp}(\lambda) \Rightarrow \mu_p = \frac{1}{\lambda} \), \( \sigma_p^2 = \frac{1}{\lambda^2} \)</p>
    <p>Test \( H_0: \mu = \mu_p \) vs \( H_A: \mu \ne \mu_p \)</p>

    <p>Observed t-statistic:
      \[ t = \frac{\bar{X} - \mu_p}{S / \sqrt{n}} \]
    </p>

    <p>Perform bootstrap resampling \( N \) times:</p>
    <ul>
      <li>Resample data with replacement → \( \bar{X}_i^*, S_i^* \)</li>
      <li>Compute:
        \[ T_i^* = \frac{\bar{X}_i^* - \mu_p}{S_i^* / \sqrt{n}} \]
      </li>
    </ul>

    <p><strong>Empirical p-value:</strong>
      \[ \text{p-value} = 2 \times \min\left( P(T^* \ge t), P(T^* \le t) \right) \]
    </p>

    <p><strong>R implementations of the bootstrap t-test:</strong></p>
    <ul>
      <li><a href="ch8_t-bootstrap_exp.html" target="_blank">ch8_t-bootstrap_exp.html</a>: Example using exponential distribution</li>
      <li><a href="ch8_t-bootstrap_skew.html" target="_blank">ch8_t-bootstrap_skew.html</a>: Example using skewed distribution</li>
    </ul>

    <hr>

    <h2>Section 8.3: Hypothesis Tests – 2 Population Means</h2>
    <p>Example: comparing two means with independent samples:</p>
    <ul>
      <li>\( X_1 \sim \mathcal{N}(\mu_1, \sigma_1^2) \)</li>
      <li>\( X_2 \sim \mathcal{N}(\mu_2, \sigma_2^2) \)</li>
    </ul>
    <p>We want to test if \( \mu_1 > \mu_2 \). Let sample statistics be:</p>
    <ul>
      <li>Sample sizes: \( n_1, n_2 \)</li>
      <li>Sample means: \( \bar{X}_1, \bar{X}_2 \)</li>
      <li>Sample standard deviations: \( S_1, S_2 \)</li>
    </ul>
    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: \mu_1 - \mu_2 = 0 \)</li>
      <li>\( H_A: \mu_1 > \mu_2 \)</li>
    </ul>
    <p><strong>Test statistic:</strong></p>
    <p>
      \[
      T = \frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}}}
      \sim t_{\nu}
      \]
      with degrees of freedom \( \nu \) approximated using Welch's method.
    </p>
    <p><strong>Observed t-value:</strong></p>
    <p>
      \[
      t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
      \]
    </p>
    <p><strong>P-value:</strong></p>
    <p>
      \[
      \text{p-value} = P(T \ge t) = 1 - \text{pt}(t, \text{df} = \nu)
      \]
    </p>
    <p><strong>Matched Pairs:</strong> If samples are paired:</p>
    <ul>
      <li>\( X_A \sim \mathcal{N}(\mu_A, \sigma_A^2) \), \( X_B \sim \mathcal{N}(\mu_B, \sigma_B^2) \)</li>
      <li>Define \( X = X_A - X_B \), then treat \( X_1, X_2, \dots \) as one sample</li>
      <li>\( X \sim \mathcal{N}(\mu_A - \mu_B, \sigma_A^2 + \sigma_B^2) \)</li>
      <li>Solve as in Section 8.1 (one-population test)</li>
    </ul>

    <hr>

    <h2>Section 8.4: Hypothesis Tests – 2 Population Proportions</h2>
    <p>Example: treatment vs control proportions</p>
    <ul>
      <li>Treatment: \( n_1 = 143, \hat{p}_1 = 75.5\% \)</li>
      <li>Control: \( n_2 = 119, \hat{p}_2 = 42.9\% \)</li>
    </ul>
    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: p_1 = p_2 \)</li>
      <li>\( H_A: p_1 > p_2 \)</li>
    </ul>
    <p><strong>From binomial model:</strong></p>
    <ul>
      <li>\( X_1 \sim \text{Binom}(n_1, p_1) \), \( X_2 \sim \text{Binom}(n_2, p_2) \)</li>
      <li>\( E[\hat{p}_1 - \hat{p}_2] = p_1 - p_2 \)</li>
      <li>\( \text{Var}[\hat{p}_1 - \hat{p}_2] = \frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2} \)</li>
    </ul>
    <p><strong>Standardized statistic:</strong></p>
    <p>
      \[
      Y = \frac{(\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)}{\sqrt{\frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2}}}
      \quad (\text{discrete})
      \]
    </p>
    <p><strong>Under \( H_0 \):</strong></p>
    <p>
      \[
      \hat{p} = \frac{\hat{p}_1 n_1 + \hat{p}_2 n_2}{n_1 + n_2}
      \quad \Rightarrow \quad
      Y = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}}
      \]
    </p>
    <p><strong>In this example:</strong></p>
    <ul>
      <li>\( \hat{p} \approx 0.6068 \)</li>
      <li>\( \text{SE} \approx 0.0606 \)</li>
      <li>\( z = 5.3795 \)</li>
      <li>\( p = P(Z \ge z) \approx 4 \times 10^{-8} \)</li>
    </ul>
    <p>This very small p-value gives strong evidence that the treatment improves the proportion.</p>

  </div>
</body>
</html>
