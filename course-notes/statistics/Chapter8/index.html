<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Hypothesis Tests (Statistic Notes)</title>
  <link rel="stylesheet" href="../../stylesheet.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    h1 {
      text-align: center;
      color: #527bbd;
      font-size: 165%;
      margin-bottom: 40px;
      border-bottom: none;
    }

    h2 {
      color: #2471A3;
      font-size: 125%;
      margin-top: 2em;
    }

    p, ul, li {
      font-size: 16px;
      line-height: 1.6;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
      margin-bottom: 30px;
    }

    table th, table td {
      border: 1px solid #ccc;
      padding: 10px;
      text-align: left;
    }

    table th {
      background-color: #f2f2f2;
    }

    hr {
      border: none;
      border-top: 1px solid #ccc;
      margin: 40px 0;
    }
  </style>
</head>

<body>
  <div id="layout-content" style="max-width: 960px; margin: 30px auto; padding: 0 50px;">

    <h1>Chapter 8: Classical Inference and Hypothesis Testing</h1>

    <h2>Section 8.1: Hypothesis Tests – 1 Population</h2>
    <p>Example: SAT scores are normally distributed with unknown mean \( \mu \), known standard deviation \( \sigma \).</p>
    <p>Population: \( X_p \sim \mathcal{N}(515, 116^2) \)</p>
    <p>From a random sample: \( \bar{X} = 555 \), \( n = 25 \)</p>

    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: \mu = 515 \)</li>
      <li>\( H_A: \mu > 515 \)</li>
    </ul>

    <p><strong>Z-statistic:</strong></p>
    <p>\( Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} = \frac{555 - 515}{116 / \sqrt{25}} = 1.724 \)</p>
    <p><strong>P-value:</strong> \( P(Z \ge 1.724) \approx 0.042 \)</p>
    <p><strong>Interpretation:</strong> Under \( H_0 \), there is a 4.2% chance to observe such a high sample mean. Hence, likely Sodor students have higher SAT scores.</p>

    <hr>

    <h2>Summary of 1 Population Results</h2>
    <table>
      <thead>
        <tr>
          <th>Sample</th>
          <th>Test Statistic</th>
          <th>Distribution</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>\( X_n \sim \mathcal{N}(\mu, \sigma^2) \), \( \sigma \) known</td>
          <td>\( Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \)</td>
          <td>\( Z \sim \mathcal{N}(0,1) \)</td>
        </tr>
        <tr>
          <td>\( X_n \sim \mathcal{N}(\mu, \sigma^2) \), \( \sigma \) unknown</td>
          <td>\( T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \)</td>
          <td>\( T \sim t(n - 1) \)</td>
        </tr>
        <tr>
          <td>\( Y \sim \text{Binomial}(n, p) \), exact binomial</td>
          <td>—</td>
          <td>Exact binomial</td>
        </tr>
        <tr>
          <td>\( Y \sim \text{Bin}(n, p) \), large \( n \)</td>
          <td>\( Z = \frac{Y \pm 0.5 - np}{\sqrt{np(1 - p)}} \)</td>
          <td>\( Z \sim \mathcal{N}(0, 1) \) with continuity correction</td>
        </tr>
      </tbody>
    </table>

    <hr>

    <h2>Section 8.2: Bootstrap t-test for Mean</h2>
    <p>Given \( X_i \sim F(\mu, \sigma^2) \) (distribution unknown), define:
      \[ T = \frac{\bar{X} - \mu}{S / \sqrt{n}} \]
    </p>
    <p>Example: \( X \sim \text{Exp}(\lambda) \Rightarrow \mu_p = \frac{1}{\lambda} \), \( \sigma_p^2 = \frac{1}{\lambda^2} \)</p>
    <p>Test \( H_0: \mu = \mu_p \) vs \( H_A: \mu \ne \mu_p \)</p>

    <p>Observed t-statistic:
      \[ t = \frac{\bar{X} - \mu_p}{S / \sqrt{n}} \]
    </p>

    <p>Perform bootstrap resampling \( N \) times:</p>
    <ul>
      <li>Resample data with replacement → \( \bar{X}_i^*, S_i^* \)</li>
      <li>Compute:
        \[ T_i^* = \frac{\bar{X}_i^* - \mu_p}{S_i^* / \sqrt{n}} \]
      </li>
    </ul>

    <p><strong>Empirical p-value:</strong>
      \[ \text{p-value} = 2 \times \min\left( P(T^* \ge t), P(T^* \le t) \right) \]
    </p>

    <p><strong>R implementations of the bootstrap t-test:</strong></p>
    <ul>
      <li><a href="ch8_t-bootstrap_exp.html" target="_blank">ch8_t-bootstrap_exp.html</a>: Example using exponential distribution</li>
      <li><a href="ch8_t-bootstrap_skew.html" target="_blank">ch8_t-bootstrap_skew.html</a>: Example using skewed distribution</li>
    </ul>

    <hr>

    <h2>Section 8.3: Hypothesis Tests – 2 Population Means</h2>
    <p>Example: comparing two means with independent samples:</p>
    <ul>
      <li>\( X_1 \sim \mathcal{N}(\mu_1, \sigma_1^2) \)</li>
      <li>\( X_2 \sim \mathcal{N}(\mu_2, \sigma_2^2) \)</li>
    </ul>
    <p>We want to test if \( \mu_1 > \mu_2 \). Let sample statistics be:</p>
    <ul>
      <li>Sample sizes: \( n_1, n_2 \)</li>
      <li>Sample means: \( \bar{X}_1, \bar{X}_2 \)</li>
      <li>Sample standard deviations: \( S_1, S_2 \)</li>
    </ul>
    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: \mu_1 - \mu_2 = 0 \)</li>
      <li>\( H_A: \mu_1 > \mu_2 \)</li>
    </ul>
    <p><strong>Test statistic:</strong></p>
    <p>
      \[
      T = \frac{(\bar{X}_1 - \bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{S_1^2}{n_1} + \frac{S_2^2}{n_2}}}
      \sim t_{\nu}
      \]
      with degrees of freedom \( \nu \) approximated using Welch's method.
    </p>
    <p><strong>Observed t-value:</strong></p>
    <p>
      \[
      t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
      \]
    </p>
    <p><strong>P-value:</strong></p>
    <p>
      \[
      \text{p-value} = P(T \ge t) = 1 - \text{pt}(t, \text{df} = \nu)
      \]
    </p>
    <p><strong>Matched Pairs:</strong> If samples are paired:</p>
    <ul>
      <li>\( X_A \sim \mathcal{N}(\mu_A, \sigma_A^2) \), \( X_B \sim \mathcal{N}(\mu_B, \sigma_B^2) \)</li>
      <li>Define \( X = X_A - X_B \), then treat \( X_1, X_2, \dots \) as one sample</li>
      <li>\( X \sim \mathcal{N}(\mu_A - \mu_B, \sigma_A^2 + \sigma_B^2) \)</li>
      <li>Solve as in Section 8.1 (one-population test)</li>
    </ul>

    <hr>

    <h2>Section 8.4: Hypothesis Tests – 2 Population Proportions</h2>
    <p>Example: treatment vs control proportions</p>
    <ul>
      <li>Treatment: \( n_1 = 143, \hat{p}_1 = 75.5\% \)</li>
      <li>Control: \( n_2 = 119, \hat{p}_2 = 42.9\% \)</li>
    </ul>
    <p><strong>Hypotheses:</strong></p>
    <ul>
      <li>\( H_0: p_1 = p_2 \)</li>
      <li>\( H_A: p_1 > p_2 \)</li>
    </ul>
    <p><strong>From binomial model:</strong></p>
    <ul>
      <li>\( X_1 \sim \text{Binom}(n_1, p_1) \), \( X_2 \sim \text{Binom}(n_2, p_2) \)</li>
      <li>\( E[\hat{p}_1 - \hat{p}_2] = p_1 - p_2 \)</li>
      <li>\( \text{Var}[\hat{p}_1 - \hat{p}_2] = \frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2} \)</li>
    </ul>
    <p><strong>Standardized statistic:</strong></p>
    <p>
      \[
      Y = \frac{(\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)}{\sqrt{\frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2}}}
      \quad (\text{discrete})
      \]
    </p>
    <p><strong>Under \( H_0 \):</strong></p>
    <p>
      \[
      \hat{p} = \frac{\hat{p}_1 n_1 + \hat{p}_2 n_2}{n_1 + n_2}
      \quad \Rightarrow \quad
      Y = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1 - \hat{p}) \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}}
      \]
    </p>
    <p><strong>In this example:</strong></p>
    <ul>
      <li>\( \hat{p} \approx 0.6068 \)</li>
      <li>\( \text{SE} \approx 0.0606 \)</li>
      <li>\( z = 5.3795 \)</li>
      <li>\( p = P(Z \ge z) \approx 4 \times 10^{-8} \)</li>
    </ul>
    <p>This very small p-value gives strong evidence that the treatment improves the proportion.</p>
     <!-- Existing content goes here -->

     <h2>Section 8.5: Type I and Type II Errors</h2>
     <p><strong>Type I Error:</strong> Rejecting \( H_0 \) when it is true. Also called a "false positive."</p>
     <p><strong>Type II Error:</strong> Not rejecting \( H_0 \) when \( H_A \) is true. Also called a "false negative."</p>
 
     <table>
       <thead>
         <tr>
           <th>Truth \ Test Result</th>
           <th>Do not reject \( H_0 \)</th>
           <th>Reject \( H_0 \)</th>
         </tr>
       </thead>
       <tbody>
         <tr>
           <td>\( H_0 \) true</td>
           <td>✓</td>
           <td>Type I Error</td>
         </tr>
         <tr>
           <td>\( H_0 \) false</td>
           <td>Type II Error</td>
           <td>✓</td>
         </tr>
       </tbody>
     </table>
 
     <p><strong>Analogy (Criminal Justice):</strong></p>
     <ul>
       <li>\( H_0 \): innocent</li>
       <li>\( H_A \): guilty</li>
     </ul>
     <table>
       <thead>
         <tr>
           <th>Truth \ Verdict</th>
           <th>Innocent</th>
           <th>Guilty</th>
         </tr>
       </thead>
       <tbody>
         <tr>
           <td>Verdict: Innocent</td>
           <td>✓</td>
           <td>Type II Error</td>
         </tr>
         <tr>
           <td>Verdict: Guilty</td>
           <td>Type I Error</td>
           <td>✓</td>
         </tr>
       </tbody>
     </table>
 
     <p>Goal is to minimize Type I Error. Lowering Type I Error rate increases Type II Error rate, and vice versa.</p>
     <p>A 5% significance level means a 5% chance of committing a Type I Error.</p>
 
     <hr>
 
     <h2>Section 8.6: Example of Type I Error in Binomial Test</h2>
     <p><strong>Example:</strong> Company claims 3% allergic reaction. You sample 100 people, and sue if 5 or more are allergic.</p>
     <p>\( H_0: p = 0.03 \), \( H_A: p > 0.03 \)</p>
     <p>Model: \( Y \sim 	ext{Binomial}(100, p) \)</p>
     <p>Reject \( H_0 \) if \( Y \ge 5 \)</p>
     <p>Calculate Type I Error:</p>
     <p>\( P(Y \ge 5 \mid p = 0.03) = 1 - P(Y \le 4) = 1 - 	ext{pbinom}(4, 100, 0.03) \approx 0.182 \)</p>
     <p><strong>Interpretation:</strong> 18.2% chance of wrongly suing when company is honest.</p>
 
     <hr>
 
     <h2>Section 8.7: Type I Error Threshold for Normal Data</h2>
     <p><strong>Example:</strong> SAT scores \( \sim N(515, 116^2) \), sample size \( n = 100 \)</p>
     <p>Want Type I Error = 10%, testing \( H_0: \mu = 515 \) vs \( H_A: \mu < 515 \)</p>
     <p>Find C such that \( P(\bar{X} < C \mid \mu = 515) = 0.10 \)</p>
     <p>\( Z = \frac{\bar{X} - 515}{116 / \sqrt{100}} \Rightarrow z = -1.282 \Rightarrow C = 515 - 1.282 \cdot \frac{116}{\sqrt{100}} = 500 \)</p>
     <p><strong>Reject \( H_0 \) if:</strong> \( \bar{X} < 500 \)</p>
 
     <hr>
 
     <h2>Section 8.8: Type II Error and Power</h2>
     <p><strong>Type II Error:</strong> \( \beta = P(\text{fail to reject } H_0 \mid H_A \text{ true}) \)</p>
     <p><strong>Power:</strong> \( 1 - \beta = P(\text{correctly reject } H_0 \mid H_A \text{ true}) \)</p>
     <p><strong>Example:</strong> Baby weights \( \sim N(30, 6^2) \), sample size \( n = 30 \)</p>
     <p>Test \( H_0: \mu = 30 \) vs \( H_A: \mu < 30 \) at \( \alpha = 0.05 \)</p>
     <p>Find critical value:</p>
     <p>
       \(
       \alpha = 0.05 \Rightarrow z = -1.645 \Rightarrow C = 30 - 1.645 \cdot \frac{6}{\sqrt{30}} = 28.2
       \)</p>
     <p>Reject \( H_0 \) if \( \bar{X} < 28.2 \)</p>
     <p>Now suppose true mean is \( \mu = 27 \), calculate power:</p>
     <p>
       \(
       P(\bar{X} < 28.2 \mid \mu = 27) = P\left(Z < \frac{28.2 - 27}{6 / \sqrt{30}}\right) = P(Z < 1.0947) = 0.863
       \)</p>
     <p><strong>Conclusion:</strong> 86.3% chance of correctly rejecting \( H_0 \) when \( \mu = 27 \)</p>

  </div>
</body>
</html>
