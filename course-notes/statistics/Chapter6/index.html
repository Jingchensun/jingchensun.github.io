<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Chapter 6: Estimation - Maximum Likelihood</title>
  <link rel="stylesheet" href="../../stylesheet.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    h1 {
      text-align: center;
      color: #527bbd;
      font-size: 165%;
      margin-bottom: 40px;
      border-bottom: none;
    }

    h2 {
      color: #2471A3;
      font-size: 125%;
      margin-top: 2em;
    }

    p, ul, li {
      font-size: 16px;
      line-height: 1.6;
    }

    hr {
      border: none;
      border-top: 1px solid #ccc;
      margin: 40px 0;
    }

    code {
      background-color: #f8f8f8;
      padding: 2px 4px;
      border-radius: 3px;
    }

    pre {
      background-color: #f4f4f4;
      padding: 10px;
      border-left: 4px solid #ccc;
      overflow-x: auto;
    }
  </style>
</head>

<body>
<div id="layout-content" style="max-width: 960px; margin: 30px auto; padding: 0 50px;">

  <h1>Chapter 6: Estimation</h1>

  <h2>Section 6.1: Maximum Likelihood Estimation (MLE)</h2>
  <p><strong>Example: Coin Flip</strong></p>
  <p>Observation: H, H, H, T</p>
  <p>Let \( p \) be the probability of heads. Then:</p>
  <p>\[
    P(HHHT) = p^3 (1 - p)
  \]</p>
  <p>Define the likelihood function:</p>
  <p>\[
    L(p) = p^3 (1 - p)
  \]</p>
  <p>To find the MLE of \( p \), solve for \( L'(p) = 0 \):</p>
  <p>\[
    L'(p) = 3p^2 - 4p^3 = p^2 (3 - 4p)
  \]</p>
  <p>Solutions: \( p = 0 \) or \( p = \frac{3}{4} \). Since \( L(0) = 0 \), the MLE is:</p>
  <p>\[
    \hat{p}_{\text{MLE}} = \frac{3}{4}
  \]</p>

  <hr>

  <h2>MLE for Discrete Distributions</h2>
  <p>Let \( X_1, ..., X_n \) be i.i.d. samples from a discrete distribution with PMF \( f(x; \theta) \).</p>
  <p>The likelihood function is:</p>
  <p>\[
    L(\theta) = \prod_{i=1}^n f(x_i; \theta)
  \]</p>

  <h3>Example: Poisson Distribution</h3>
  <p>PMF: \( f(x; \lambda) = \frac{\lambda^x e^{-\lambda}}{x!} \)</p>
  <p>Observed data: \( x_1 = 3, x_2 = 4, x_3 = 3, x_4 = 7 \)</p>
  <p>\[
    L(\lambda) = \frac{\lambda^{17} e^{-4\lambda}}{3! \cdot 4! \cdot 3! \cdot 7!}
  \]</p>
  <p>Log-likelihood:</p>
  <p>\[
    \ln L(\lambda) = 17 \ln \lambda - 4\lambda - \ln(\#)
  \]</p>
  <p>Differentiating and solving:</p>
  <p>\[
    \frac{17}{\lambda} - 4 = 0 \Rightarrow \hat{\lambda}_{\text{MLE}} = \frac{17}{4}
  \]</p>

  <hr>

  <h2>MLE for Continuous Distributions</h2>
  <p>Let \( X_1, ..., X_n \) be i.i.d. samples from a continuous distribution with PDF \( f(x; \theta) \).</p>
  <p>\[
    L(\theta) = \prod_{i=1}^n f(x_i; \theta)
  \]</p>

  <h3>Example: Exponential Distribution</h3>
  <p>PDF: \( f(x; \lambda) = \lambda e^{-\lambda x}, \quad x \ge 0 \)</p>
  <p>\[
    L(\lambda) = \lambda^n e^{-\lambda \sum x_i}
  \]</p>
  <p>Log-likelihood:</p>
  <p>\[
    \ln L(\lambda) = n \ln \lambda - \lambda \sum x_i
  \]</p>
  <p>Solving:</p>
  <p>\[
    \frac{n}{\lambda} - \sum x_i = 0 \Rightarrow \hat{\lambda}_{\text{MLE}} = \frac{n}{\sum x_i} = \frac{1}{\bar{x}}
  \]</p>

  <hr>

  <h2>MLE for Cauchy Distribution (Numerical Optimization)</h2>
  <p>Distribution: \( X \sim \text{Cauchy}(\theta) \)</p>
  <p>PDF: \( f(x; \theta) = \frac{1}{\pi(1 + (x - \theta)^2)} \)</p>
  <p>Data: \( x = [1, 2, 3] \)</p>
  <p>Log-likelihood:</p>
  <p>\[
    \ln L(\theta) = -3 \ln \pi - \sum_{i=1}^3 \ln(1 + (x_i - \theta)^2)
  \]</p>
  <p>Score equation:</p>
  <p>\[
    \sum_{i=1}^3 \frac{2(x_i - \theta)}{1 + (x_i - \theta)^2} = 0
  \]</p>
  <p>This is nonlinear in \( \theta \), so solve numerically.</p>

  <h3>R Code for Optimization:</h3>
  <pre><code>
x <- c(1, 2, 3)
logL <- function(theta) sum(log(dcauchy(x, theta)))
optimize(logL, interval = c(0, 4), maximum = TRUE)
  </code></pre>
  <p><strong>Output:</strong> maximum = 2, objective = -4.8205</p>

  <hr>

  <h2>MLE with Two Parameters in Normal Distribution</h2>
  <p>Distribution: \( X \sim N(\mu, \sigma^2) \)</p>
  <p>PDF: \( f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi} \sigma} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right) \)</p>

  <p>Log-likelihood:</p>
  <p>\[
    \ln L(\mu, \sigma) = -\frac{n}{2} \ln(2\pi) - n \ln \sigma - \frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2
  \]</p>

  <p><strong>MLE for \( \mu \):</strong></p>
  <p>\[
    \frac{\partial}{\partial \mu} \ln L = 0 \Rightarrow \mu = \frac{1}{n} \sum x_i = \bar{x}
  \]</p>

  <p><strong>MLE for \( \sigma \):</strong></p>
  <p>\[
    \frac{\partial}{\partial \sigma} \ln L = 0 \Rightarrow \sigma^2 = \frac{1}{n} \sum (x_i - \bar{x})^2
  \]</p>

  <p><strong>Final MLE Estimates:</strong></p>
  <p>\[
    \hat{\mu}_{\text{MLE}} = \bar{x}, \quad 
    \hat{\sigma}_{\text{MLE}} = \sqrt{ \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2 }
  \]</p>

</div>
</body>
</html>
